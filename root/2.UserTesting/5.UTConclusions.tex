
\subsection{Conclusions and considerations}

The team conducted the user testing in order to confirm the results that came out from the heuristic inspection and to spot new issues and difficulties that testers encountered when navigating UNICEF’s website. The tasks were defined based on the main problems found during the inspection and the testing session was carried out with 20 people.\\

All the tasks have a high percentage of success (78\%; 82\%; 87\%; 92\%, 85\%, 82\%), meaning that the testers succeeded in completing the goal even though sometimes they followed a different path than the established one. Task 1 has the lowest success rate, it was considered the most difficult by testers and the average time spent on the task is very near to the maximum time set by evaluators. Even though task number 3 has a high number of alternative path (5) the success rate is 87\%, unlike task number 2 that has a success rate of 82\% but only 2 alternative paths and the time spent exceeds the time set by the team.
Moreover, the average time spent on each task resulted to be quite consistent with the one predicted by the team before performing the testing. The average time spent on task number 4 is two minutes shorter than the one set and for tasks number 2 and number 6 it is higher than expected.
Task number 2 is the one with the higher number of errors (1.60), being quite different from the values recorded during the other tasks, and with the higher number of frustrations (0.40). Testers had difficulties in finding the right page for donating to Afghanistan, due to the many "Donate" buttons that however did not present the specific option for Afghanistan. Moreover, the differing visual aspect of the "Donate" buttons confused people, since they were expecting different interactions because of the various styles of the buttons. This probably led to frustrations and to annoyance.
Task number 1 and task number 4 present the higher number of disorientations, stops and wandering periods. Being new to the website, users may had to understand the structure of the website for the first time while trying to accomplish task number 1. Instead, during task number 4 users were bombarded by an overload of information in both textual and visual form and this may have lead to being astonished, requiring some time to understand which content to prioritize.

Besides quantitative indicators, the team decided to also focus on qualitative indicators that could provide more insights about the actual problems found during the navigation. For this reason, comments and observations were taken both from the perspective of the evaluators and from the ones of each tester, as well as annotating moments of disorientation, wandering and frustrations. The mix between quantitative and qualitative indicators, together with the post-test questionnaire, allowed the team to have a clearer understanding regarding the perspective of testers that never used UNICEF’s website before.\\

The categories addressed were: Usability, Content, Interaction and Navigation, Aesthetic, Organization and Consistency. In general, for each category the average number of category critics (n CAT critics) is higher than the number of category praises (n CAT Praises), representing 75,14\%. The Aesthetic category is the one that received less comments by the testers, but this is understandable since none of the testers had a design background, as well as not being the focus of the test. Consistency is another aspect that was not really addressed by many users, but this could also be due to the short time spent on task and the lack of a professional background that may have allowed them to recognise inconsistencies. However, testers mainly commented in a negative way regarding this category: whether aware or not, the lack of consistency through the website may have implied a higher cognitive effort to succeed in the task. One example is that testers expected different functions from the different “Donate” buttons, and they expressed confusion when all of them led to the same page. 
The categories of Interaction and Navigation, Organisation and Content were highly criticised by users. 
The Organisation category received 40 critics, while only 4 positive comments, showing how serious this aspect was considered to be and how severily affected usability, with a total score of 1.98. At the same time, testers did not find the interaction between and inside pages pleasant or satisfactory, totalling a score of 2.53, with 35 critics and 16 praises.
Regarding the Content category, testers found difficulties in finding the content requested in the page due to the amount of information displayed and the poor relevance. Many of them complained about the images being too big and thus distracting and confusing. The category score was 3.12, with 20 critics and 7 praises.\\
 
One key aspect that emerged from the user testing, and that during the heuristic inspection was slightly overlooked, is the problems connected to information architecture. Despite having a high percentage of success, testers often followed alternative paths to complete the task and made mistakes along the way. 
By observing testers performing the tasks, it was possible to understand that alternative paths and mistakes mainly depended on the difficulties in finding the correct page/section in the main menu. The amount of content, the repetitions and the lack of clear distinction between the various sections led users to get lost in the website and thus trying different options before completing the task. 
For sure, this aspect created a lot of frustration and stress in the testers, who had to make a greater effort to perform tasks that are considered to be common in a website such UNICEF. This is reflected in the fact that 73.23\% of comments and observations on the tasks are negative. However, it is fair to highlight how the team created the tasks in order to verify problems already identified in the inspection (and to discover new ones), so this results was expected.
Many testers identified the website as complex, unclear, confusing and saturated with information. They also described it as informative and visually pleasing, but they were the minority.\\

The categories analysed during the user testing were more than the ones used for the inspection and this allowed the team to go deeper into understanding the users' perception of the website. In particular, the category of Experience and Usability scored a total of 2.18, with 24 critics and 12 praises, highlighting how users agreed on the unnecessary complex nature of the website, as well as it being cumbersome to use. 
Having a direct opinion of testers on using or not using the website frequently was helpful to assess how, even for non-experts, the experience resulted unpleasant and awkward, compromising UNICEF's aim to raise awareness and collect money for supporting their operation.
In conclusion, it can be stated that the user testing was helpful for confirming the problems found during the inspection (inconsistency, hierarchy, overload of information) and to also identify the importance of improving the information architecture in order to facilitate the navigation and thus enhance the overall usability of the website.
