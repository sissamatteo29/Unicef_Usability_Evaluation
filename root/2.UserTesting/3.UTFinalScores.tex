
\subsection{Usability indicators and scores}
To properly evaluate the User Testing Analysis the following usability indicators were used:\\

\vspace{0.05cm}

\noindent\textbf{Quantitative indicators:}
\begin{itemize}
	\item Completion rate
	\item Task duration
	\item Task difficulty
	\item Category score
	\item Deviation from predicted Task duration
\end{itemize}

\noindent\textbf{Qualitative indicators:}
\begin{itemize}
	\item Positive and negative comments and observations
	\item Category praises and critics
	\item Alternative solutions
	\item Errors
	\item Disorientation, stops, wandering periods
	\item Frustration
\end{itemize}

\vspace{0.5cm}

To properly understand the meaning of these indicators and how they were used during the study, there will be given their respective definitions, how they are computed and for qualitative indicators how they are translated to quantitative ones.

\vspace{0.25cm}

\textbf{Completion rate:} is a per task measurement of the completion of a task. Given a task the completion rate is derived by averaging the successes and failures of all the 20 participants and then expressing it in percentage. To calculate the average, the following points were assigned to the different possible "Task Completion" values:
\begin{itemize}
	\item Failure: 1
	\item Partial: 2
	\item Completed ASSISTED: 3
	\item Completed ALT: 4
	\item Completed: 5
\end{itemize}

\vspace{0.25cm}

\textbf{Task duration:} is a per task measurement of the duration of a task. Given a task the task duration is derived by averaging the "Elapsed time" values of all the 20 participants.

\vspace{0.25cm}

\textbf{Task difficulty:} is a per task measurement of the perceived difficulty of a task from the point of view of the participant. Given a task the task difficulty is derived by averaging the "Task difficulty" values of all the 20 participants. The task difficulty is a value bounded between 1 and 5, going from easy to hard.

\vspace{0.25cm}

\textbf{Category score:} is a per category measurement of its perceived quality from the point of view of the participant. The chosen categories are: Experience and Usability, Content, Interaction and Navigation, Aesthetic, Organization, Consistency, Task Sheet Evaluation. They can all be found in the Post Test Questionnaire. Given a category the category score is derived by averaging the scores of all the 20 participants for all the questions inside that particular category. To calculate the average, the following points were assigned to the different possible values in case of a positive statements (Questions: 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18):
\begin{itemize}
	\item Strongly Disagree: 1
	\item Disagree: 2
	\item Neutral: 3
	\item Agree: 4
	\item Strongly Agree: 5
\end{itemize}
For negative statements (Questions: 4, 5, 7, 16) the opposite convention has been applied.
The category score is a value bounded between 1 and 5 (bad - good).

\vspace{0.25cm}

\textbf{Deviation from predicted Task duration:} is a per task measurement of the deviation from the predicted task duration. Given a task the deviation is derived by averaging the deviation values of all the 20 participants. A deviation value is obtained by subtracting the predicated value from the "Elapsed time" value. A negative value indicates that the participant took less time to complete the task, while a positive value indicates that they took more time to complete it.

\vspace{0.25cm}

\textbf{Positive and negative comments and observations:} is a global indicator of the opinions of the participants. To translate this indicator into a quantitative one the number of occurrences of the 2 types were counted separately, leading to 2 new quantitative indicators: "Number of positive comments and observations" and "Number of negative comments and observations". The considered comments and observations are the ones present in the "Task Record Sheet" and in the "Post Test Questionnaire" dedicated sections. 

\vspace{0.25cm}

\textbf{Category praises and critics:} is a per category indicator of the praises and critics given by the participant and by the annotated comments of the evaluator during the user testing. The chosen categories are: Experience and Usability, Content, Interaction and Navigation, Aesthetic, Organization, Consistency. To translate this indicator into a quantitative one the number of praises and critics per category were counted, leading to 2 new quantitative indicators: "Number of category praises" and "Number of category critics". The considered comments and observations are the ones present in the "Task Record Sheet" and in the "Post Test Questionnaire" dedicated sections.

\vspace{0.25cm}

\textbf{Alternative solutions:} is a per task indicator of the behaviour of the participant during the user testing that led to the correct solution via a different way. To translate this indicator into a quantitative one the number of unique alternative ways were counted, leading to a new quantitative indicator: "Number of alternative solutions". An alternative way is a different sequence of steps and pages visited from the planned solution, which still led the participant to the planned solution. This occurrence is marked by the "Task Completion" value "Completed ALT".

\vspace{0.25cm}

\textbf{Errors:} is a per task indicator of the behaviour of the participant during the user testing that led to incorrect solutions or incorrect paths. To translate this indicator into a quantitative one the number of incorrect solutions and paths were counted and averaged, leading to a new quantitative indicator: "AVG Number of errors". An incorrect solution is a solution that the participant deemed as correct while it was not (failed task are not taken into consideration). An incorrect path is a path that would have not led the participant to the solution, and from which the participant had to roll back and try another path.

\vspace{0.25cm}

\textbf{Disorientations, stops, wandering periods:} is a per task indicator of the behaviour of the participant during the user testing in which the participant showed disorientation and wandering periods and made reflective stops, leading to a new quantitative indicator: "AVG Number of disorientation, stops, wandering periods". To translate this indicator into a quantitative one the number of occurrences of these behaviours were counted  and averaged.

\vspace{0.25cm}

\textbf{Frustration:} is a per task indicator of the behaviour of the participant during the user testing in which the participant showed frustration. To translate this indicator into a quantitative one the number of occurrences of this behaviour were counted  and averaged, leading to a new quantitative indicator: "AVG Number of frustrations".

\newpage

\subsubsection*{Result tables}
The following tables and their results are the outcomes of the analysis and aggregation of all evaluators' works, which are clearly and fully reported in the respective Annex sections.\\
For brevity and to better display the data the following indicators has been shorten to:
\begin{itemize}
	\item Deviation from predicted Task duration $\rightarrow$ Deviation
	\item Number of alternative solutions $\rightarrow$ n ALT Solutions
	\item AVG Number of errors $\rightarrow$ AVG n Errors
	\item AVG Number of disorientations, stops, wandering periods $\rightarrow$ AVG n DSWs
	\item AVG Number of frustrations $\rightarrow$ AVG n Frustrations
	\item Number of category praises $\rightarrow$ n CAT Praises
	\item Number of category critics $\rightarrow$ n CAT Critics
	\item Number of positive comments and observations $\rightarrow$ n Positive C\&O
	\item Number of negative comments and observations $\rightarrow$ n Negative C\&O
\end{itemize}

\begin{table}[h]
	\centering
	\begin{tabularx}{\textwidth}{|*{5}{>{\centering\arraybackslash}X|}}
		\hline
		Task & \textbf{Completion rate} & \textbf{Task duration} & \textbf{Task difficulty} & \textbf{Deviation} \\ \hline
		1 & 78.00\% & 5:43 & 3.55 & -0:17 \\ \hline
		2 & 82.00\% & 4:54 & 3.05 & +0:54 \\ \hline
		3 & 87.00\% & 2:43 & 2.35 & -0:17 \\ \hline
		4 & 92.00\% & 3:59 & 2.8 & -2:01 \\ \hline
		5 & 85.00\% & 3:22 & 2.4 & +0:22 \\ \hline
		6 & 82.00\% & 3:54 & 2.6 & +0:54 \\ \hline
	\end{tabularx}
	\caption{\textit{Task Evaluation (Part 1)}}
	\label{tab:task_evaluation_part1}
\end{table}

\begin{table}[h]
	\centering
	\begin{tabularx}{\textwidth}{|*{5}{>{\centering\arraybackslash}X|}}
		\hline
		Task & \textbf{n ALT Solutions} & \textbf{AVG n Errors} & \textbf{AVG n DSWs} & \textbf{AVG n Frustrations} \\ \hline
		1 & 3 & 0.50 & 0.80 & 0.15 \\ \hline
		2 & 2 & 1.60 & 0.40 & 0.40 \\ \hline
		3 & 5 & 0.50 & 0.35 & 0.10 \\ \hline
		4 & 2 & 0.25 & 0.80 & 0.15 \\ \hline
		5 & 4 & 0.20 & 0.30 & 0.05 \\ \hline
		6 & 3 & 0.75 & 0.30 & 0.05 \\ \hline
	\end{tabularx}
	\caption{\textit{Task Evaluation (Part 2)}}
	\label{tab:task_evaluation_part2}
\end{table}

\begin{table}[h]
	\centering
	\begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}p{4.5cm}|*{3}{>{\centering\arraybackslash}X|}}
		\hline
		\textbf{Category} & \textbf{Category score} & \textbf{n CAT Praises} & \textbf{n CAT Critics} \\ \hline
		Experience and Usability & 2.18 & 12 & 24 \\ \hline
		Content & 3.12 & 7 & 20 \\ \hline
		Interaction and Navigation & 2.53 & 16 & 35 \\ \hline
		Aesthetic & 3.1 & 4 & 5 \\ \hline
		Organization & 1.98 & 4 & 40 \\ \hline
		Consistency & 3.28 & 2 & 12 \\ \hline
		Task Sheet Evaluation & 4.05 & - & - \\ \hline
	\end{tabularx}
	\caption{\textit{Category Evaluation}}
	\label{tab:category_evaluation}
\end{table}

\begin{table}[h]
	\centering
	\begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}p{5cm}|>{\centering\arraybackslash}X|}
		\hline
		\textbf{Indicator} & \textbf{Value} \\ \hline
		n Positive C\&O & 53 \\ \hline
		n Negative C\&O & 145 \\ \hline
	\end{tabularx}
	\caption{\textit{Global Evaluation}}
	\label{tab:global_evaluation}
\end{table}
