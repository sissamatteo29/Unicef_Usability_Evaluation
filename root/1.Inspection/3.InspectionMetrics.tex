
\subsection{Metrics}

To perform a consistent analysis, it is necessary to define a set of numerical metrics to evaluate each heuristic in a uniform way.
Initially, the team engaged in a discussion about the best scale to use and the relative qualitative value. The team was undecided whether to use a scale of 0 to 5 or 1 to 5 and about which kind of definition to assign to each number.
The final decision fell on using a numerical scale of 1 to 5 in order to avoid overly neutral judgments, as well as setting a clear difference between each number of the scale in terms of qualitative definition. 

Since all the definitions of heuristics were interpreted with a positive approach, the team defined the following evaluation metrics scale.
\begin{itemize}
    \item \textbf{1 - Totally Unsatisfied:} The heuristic is totally unsatisfied, as the aspect addressed does not perform its intended function. This harshly compromises an effective and fluid interaction with the website as it may involve a high cognitive effort.
    \item \textbf{2 - Mildly Wrong:} The website presents significant limitations or flaws that hinder its overall effectiveness, resulting in compromising the usability in a meaningful way.
    \item \textbf{3 - Acceptable:} The website presents minor issues or inefficiencies that require some effort to overcome, but it generally meets basic user needs without significant flaws.
    \item \textbf{4 - Almost Satisfied:} Minor limitations or areas for improvement are present and they require minimal effort from users, not significantly impacting the overall usability.
    \item \textbf{5 - Totally Satisfied:} The heuristic is totally satisfied, as the website presentes clear and intuitive patterns, allowing users to accomplish their goals effectively.
\end{itemize}

To perform the individual inspection easily, the team created a common inspection sheet where each evaluator could assign the value to each heuristic, add a comment and meaningful examples. Having a shared methodology to perform the analysis was crucial for the team to perform a coherent inspection, but most importantly to facilitate the discussion and the final assignment of scores.