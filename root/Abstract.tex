
\section{Abstract}

Usability evaluation of a website can be defined as a systematic and methodical approach to assess the ease of use of a website, intended as the degree of simplicity and intuitiveness with which target users are able to navigate the website, accomplish tasks, find useful information.

This document illustrates the methodology adopted and the results obtained for the usability evaluation of the \href{https://www.unicef.org/}{official Unicef website}.

The structure of this report can be divided into three main sections, completed by a final annex.

In the first chapter, the inspection procedure and its results are described. Inspection is a kind of usability evaluation practice that involves usability experts to examine the website and identify issues and problems to be solved. More specifically, the methodology employed here is heuristic-based, which means that the assessment of the website is centered around some heuristics that are relevant for the software product under analysis. 
For all heuristics, the experts are required to assign a score to the website individually and then discuss together about their marks. The result of this discussion should produce an unanimous score agreed by all evaluator for each heuristic.\\
In this chapter, the final scores agreed by all evaluator on the \href{https://www.unicef.org/}{official Unicef website} are illustrated.

The second chapter is about another relevant usability evaluation procedure which is user testing. In this case, possible users of the website (which are not usability experts) are required to complete some predefined tasks on the website itself. Their behavior and actions are observed by an expert while they accomplish the tasks and important usability concerns or issues are elicited from this observations.

Finally, the third chapter concludes the document with a set of final considerations about the methodology and techniques adopted for assessing the \href{https://www.unicef.org/}{official Unicef website}. A comparison of the inspection and user testing practices is also offered here.

The annex adds some important information that might be complementary for the reader to delve deeper and understand better the results illustrated in the previous chapters. For instance, while the first chapter on inspection only shows and describes the final scores agreed by all evaluators, the annex has dedicated subsections in which it is possible to see the individual scores assigned by the evaluators for the website.
